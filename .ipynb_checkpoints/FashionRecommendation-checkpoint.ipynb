{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vYdCbgmn_oAH"
   },
   "source": [
    "## **Importing all the important libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Np5XUGk_8He"
   },
   "outputs": [],
   "source": [
    "#importing all the important libraries\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets,models,transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fl3U2ErK_9xY"
   },
   "source": [
    "**labeling the cloth classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JqVWcaT3ADQS"
   },
   "outputs": [],
   "source": [
    "class_label = {'2':'Blazer', '3':'Blouse'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3W61nqYwAIyr"
   },
   "source": [
    "# **Transforming the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tU8csEJrGu4z"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),                                                 # transform ‘to_tensor’ will be used to convert the PIL image to a PyTorch tensor (multidimensional array)\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKfFpoTpASLA"
   },
   "source": [
    "# **Importing the pretrained ResNet Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Gze9bmGnAZWA",
    "outputId": "d9fbc535-a05b-4e80-f95a-d5c55cded5f0"
   },
   "outputs": [],
   "source": [
    "model_ts = torch.load('trained_model.pt')\n",
    "model_ts.eval()\n",
    "model_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cGVGS4GTAfii"
   },
   "source": [
    "**Building a activation function to get the output of first fully connected layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sNM4haYMFs4g"
   },
   "outputs": [],
   "source": [
    "# building the function to get the output of first fully connected layer\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hVh27OhpBDB2"
   },
   "source": [
    "**Define a function to get a path of each input image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "otm5YDikFu_7"
   },
   "outputs": [],
   "source": [
    "# Define a function for getting a path of each input image\n",
    "\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7NjsMXsFyG4"
   },
   "outputs": [],
   "source": [
    "# Getting the first fully connected layer for the each and every image in train dataset and store the data into df_train dataframe\n",
    "\n",
    "data_dir_train = '/content/drive/My Drive/Colab Notebooks/MVC/data/train'                      # path of image directory\n",
    "dataset_train = ImageFolderWithPaths(data_dir_train, transform=data_transforms['train'])        # our custom dataset\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train)   \n",
    "\n",
    "# generate a empty dataset\n",
    "df_train = pd.DataFrame()\n",
    "\n",
    "# iterating over a train dataset\n",
    "\n",
    "for inputs, label, img_path in dataloader_train:\n",
    "      model_ts.avgpool.register_forward_hook(get_activation('name'))              #  first fully connected layers output\n",
    "      input_img = inputs                                                   # input image of size [1, 3, 224, 224]\n",
    "      output = model_ts(input_img)                                                      # fit the image to above model and get output of first fully connected layer of that image\n",
    "      output_FC = np.array(activation['name'])                                                    # convert above output to list\n",
    "      output_FC = output_FC.reshape(1,2048)                       \n",
    "      label = img_path[0].split('/')[-2]                                                # getting a category label from image path\n",
    "      data = {\"category\":label,\"img_path\":img_path[0], \"img_vec\":output_FC}             # fitting the above data to the empty datafrme\n",
    "      df_train = df_train.append(data, ignore_index=True) \n",
    "\n",
    "  \n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hxp625IdF63L"
   },
   "outputs": [],
   "source": [
    "# Getting the first fully connected layer for the each and every image in valid dataset and store the data into df_valid dataframe\n",
    "\n",
    "data_dir_valid = 'data/valid'                      # path of image directory\n",
    "dataset_valid = ImageFolderWithPaths(data_dir_valid, transform=data_transforms['valid'])        # our custom dataset\n",
    "\n",
    "dataloader_valid = torch.utils.data.DataLoader(dataset_valid)                                   \n",
    "\n",
    "\n",
    "# generate a empty dataset\n",
    "df_valid = pd.DataFrame()\n",
    "\n",
    "\n",
    "# iterating over a valid dataset\n",
    "\n",
    "for input, label, img_path in dataloader_valid:\n",
    "      model_ts.avgpool.register_forward_hook(get_activation('name'))              #  first fully connected layers output\n",
    "      input_img = input#.to(device)                                                     # input image of size [1, 3, 224, 224]\n",
    "      output = model_ts(input_img)                                                      # fit the image to above model and get output of first fully connected layer of that image\n",
    "      output_FC = np.array(activation['name'])                                                   # convert above output to list                        \n",
    "      output_FC = output_FC.reshape(1,2048)\n",
    "      label = img_path[0].split('/')[-2]                                                # getting a category label from image path\n",
    "      data = {\"category\":label,\"img_path\":img_path[0], \"img_vec\":output_FC}             # fitting the above data to the empty datafrme\n",
    "      df_valid = df_valid.append(data, ignore_index=True) \n",
    "\n",
    "\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "aLXAsP1ta707",
    "outputId": "6ea8e510-f719-4321-b4a6-32869fa46a22"
   },
   "outputs": [],
   "source": [
    "# Getting the first fully connected layer for the each and every image in train dataset and store the data into df_test dataframe\n",
    "\n",
    "data_dir_test = 'data/test'                      # path of image directory\n",
    "dataset_test = ImageFolderWithPaths(data_dir_test, transform=data_transforms['test'])        # our custom dataset\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test)   \n",
    "\n",
    "# generate a empty dataset\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "# iterating over a train dataset\n",
    "\n",
    "for input, label, img_path in dataloader_test:\n",
    "      model_ts.avgpool.register_forward_hook(get_activation('name'))              #  first fully connected layers output\n",
    "      input_img = input#.to(device)                                                     # input image of size [1, 3, 224, 224]\n",
    "      output = model_ts(input_img)                                                      # fit the image to above model and get output of first fully connected layer of that image\n",
    "      output_FC = np.array(activation['name'])                                                    # convert above output to list\n",
    "      output_FC = output_FC.reshape(1,2048)                       \n",
    "      label = img_path[0].split('/')[-2]                                                # getting a category label from image path\n",
    "      data = {\"category\":label,\"img_path\":img_path[0], \"img_vec\":output_FC}             # fitting the above data to the empty datafrme\n",
    "      df_test = df_test.append(data, ignore_index=True) \n",
    "\n",
    "  \n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "lRsld9cTSJGL",
    "outputId": "dfc7d0a0-a861-4262-eaf3-837b14a30b1f"
   },
   "outputs": [],
   "source": [
    "# downloading a dataframes\n",
    "from google.colab import files\n",
    "\n",
    "df_train.to_csv('df_train.csv') \n",
    "\n",
    "\n",
    "df_valid.to_csv('df_valid.csv') \n",
    "\n",
    "\n",
    "df_test.to_csv('df_test.csv') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HR5K591PCJC7"
   },
   "source": [
    "**Importing a attributes dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "h42R9fxelygV",
    "outputId": "fbb4d4fb-f95c-460d-aec6-dc879f96b299"
   },
   "outputs": [],
   "source": [
    "path = \"attributes1.csv\"  # paste the path attributes1.csv file\n",
    "#path = \"/content/drive/My Drive/Colab Notebooks/MVC/data/attributes1.csv\"\n",
    "attributes1 = pd.read_csv(path)\n",
    "attributes1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "ZiaL6IbY1gMc",
    "outputId": "f8a42da2-b47d-49a1-da42-d5f5e059d230"
   },
   "outputs": [],
   "source": [
    "attributes = attributes1.drop(['Unnamed: 0','Unnamed: 0.1','image_name','sold'], axis = 1)         # dropping the Image_name column\n",
    "attributes = attributes.rename_axis('attributes_vec').values   # converting the dataframe to the numpy array\n",
    "attributes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s2QczY2sLXku"
   },
   "source": [
    "**choosing the image on basis of attributes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GRBMMfHk_Sod"
   },
   "outputs": [],
   "source": [
    "def choose_image(attributes_vector):\n",
    "    att_sim = []\n",
    "    for i in range(len(attributes)):\n",
    "        cos_simm = np.dot(attributes_vector,attributes[i]) / (np.linalg.norm(attributes_vector) * np.linalg.norm(attributes[i]))   # caluclating cosine similarity between attibutes vec\n",
    "        att_sim.append(cos_simm)\n",
    "    att_sim = np.array(att_sim)                                            # convert list ot numpy arraay\n",
    "    \n",
    "    list1 = np.where(att_sim == np.amax(att_sim))                  # getting a indices of all the maximum  values from att\n",
    "    list1 = list1[0]\n",
    "\n",
    "    add = 0\n",
    "    for i in range(len(list1)):\n",
    "        a = attributes1[\"sold\"][i]\n",
    "        add += a                                                    # adding entries of sold column on the basis of indices from list1\n",
    "\n",
    "    p = []\n",
    "    for i in range(len(list1)):\n",
    "        p1 = attributes1[\"sold\"][i] / add\n",
    "        p.append(p1)                                                 # getting a probabilty of each entry of sold column on the basis of indices from list1 \n",
    "    \n",
    "    #p = p.to_numpy()\n",
    "\n",
    "    list2 = np.random.choice(list1, 6, p=p, replace=False)                       # getting a list of indices(top 6) on the basis of probability p randomly\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    for j in range(len(list2)):\n",
    "        i = list2[j]\n",
    "        categoty_label = df_test[\"category\"][i]       # get a category_label from index       \n",
    "        category_name = class_label[categoty_label]    # get a category from category_label using class_label dictionary\n",
    "        img = mpimg.imread(df_test[\"img_path\"][i])    # reading a image using mpimg\n",
    "        ax = fig.add_subplot(2,3,j+1)\n",
    "        ax.imshow(img)\n",
    "        title = str(j) + \" \" + category_name\n",
    "        plt.title(title)\n",
    "\n",
    "    return list2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xH7yEGGfLs4r"
   },
   "source": [
    "**Recommending the images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FPJkSTxRLmjn"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "loader = transforms.Compose([transforms.RandomResizedCrop(224), transforms.ToTensor()])   # passing the input image through transforms\n",
    "\n",
    "def recommended_images(number):\n",
    "    #list = np.random.choice(list1, 6, p=p)                       # getting a list of indices on the basis of probability p\n",
    "    a = list2[number]                                                      # getting a index of above choosen image\n",
    "\n",
    "    attributes1[\"sold\"][a] = attributes1[\"sold\"][a] + 1                  # adding 1 to the sold column each time when customer chooses that image\n",
    "\n",
    "    image_name = df_test[\"img_path\"][a]                                  # getting a path of that image from above index\n",
    "\n",
    "\n",
    "    # Using PyTorch Cosine Similarity\n",
    "    cos_sim = []\n",
    "    for i in range(len(df_train[\"category\"])):\n",
    "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        vec1 = torch.as_tensor(df_test[\"img_vec\"][a])                      # # getting a vec of that image from above index from df_test dataframe\n",
    "        vec1.requires_grad = True\n",
    "        vec2 = torch.as_tensor(df_train[\"img_vec\"][i])  \n",
    "        vec2.requires_grad = True           \n",
    "        cos_similarity = cos(vec1, vec2)             # calculate the cos angle between output_FC and train img_vec\n",
    "        cos_similarity = cos_similarity.item()                       \n",
    "        cos_sim.append(cos_similarity)\n",
    "\n",
    "    cos_sim = np.array(cos_sim)                                             # convert list ot numpy arraay\n",
    "\n",
    "    \n",
    "    \n",
    "    # run through the list \n",
    "    list3 = cos_sim.argsort()[-6:][::-1]               # top 6 maximum value of cos_similarity list\n",
    "    \n",
    "    # showing reference image\n",
    "    img1 = mpimg.imread(image_name)\n",
    "    plt.figure(figsize=(7,7))\n",
    "    cat_label = df_test[\"category\"][a]       # get a category_label from index       \n",
    "    cat_name = class_label[cat_label]    # get a category from category_label using class_label dictionary\n",
    "    title = 'Reference_image' + ': ' + cat_name\n",
    "    plt.title(title)\n",
    "    plt.imshow(img1)\n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    #print('Recommended images')\n",
    "    for j in range(len(list3)):\n",
    "        i = list3[j]\n",
    "        categoty_label = df_train[\"category\"][i]       # get a category_label from index       \n",
    "        category_name = class_label[categoty_label]    # get a category from category_label using class_label dictionary\n",
    "        img = mpimg.imread(df_train[\"img_path\"][i])    # reading a image using mpimg\n",
    "        ax = fig.add_subplot(2,3,j+1)\n",
    "        ax.imshow(img)\n",
    "        plt.title(category_name)\n",
    "\n",
    "\n",
    "    return vec3\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell the input is randomly inputted in a one-hot encoded format.That is if your prefer weather condition is sunny\n",
    "and you are attending an official event then the sunny and official variables are to be set to 1 while the rest are set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GNlE1_7zLIdt"
   },
   "outputs": [],
   "source": [
    "# change this cell according to your attribute preferce\n",
    "sunny = 1\n",
    "rainy = 0\n",
    "cold  = 0\n",
    "normal = 0\n",
    "party = 0\n",
    "casual = 0\n",
    "official = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R8bXFQ55NL_f",
    "outputId": "1bb48102-805d-4fcf-de78-91db0305f8b5"
   },
   "outputs": [],
   "source": [
    "# converting above values in numpy array\n",
    "att_vec = np.array([sunny,rainy,cold,normal,party,casual,official], dtype=float)\n",
    "att_vec"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FashionRecommendation",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
